ACKNOWLEDGEMENTS
	I would take this opportunity to thank everyone who helped me with this project. I would like to thank my Project Coordinator Dr. Sumathi I.R, Assistant Professor, Department of Mathematics, Amrita Vishwa Vidyapeetham, who constantly guided me. I would like to thank her for taking a considerable amount of time from his busy schedule to help with this mini project. I would like to express my sincere gratitude towards Dr Somasundaram, Chairperson and all the faculty members of the Department of Mathematics, Amrita Vishwa Vidyapeetham for supporting the vision that I believed in which has made this mini project a reality.
	Lastly, I am especially indebted to my parents, family members and friends for their support, motivation, love and affection that have providing me with immense motivation and strength to finish this project successfully.
																																										         (Ranjit N)






Contents
Certificate									  2
Declaration 									  3
Acknowledgements 								  4
Abstract										  7
1. Introduction									  8
   1.1. Project Overview							        	   8
   1.2. Project Goals								   9
   1.3. Report Structure							 	   9
2. Motivation									10
   2.1. Interview Skills Importance						 10
   2.2. Traditional Practice Challenges					 	 10
   2.3. AI Potential									 11
3. Problem Statement							12
   3.1. Lack of Practice Tools							 12
   3.2. Need for Realism								 12
4. AI Interviewer Solution							13
   4.1. Concept									 13
   4.2. Multi-Agent System							 13
   4.3. Technical Architecture							 14
   4.4. Agent Implementation Details						 15
   4.5. Communication Protocol						 	 16
5. System Implementation							18
   5.1. Backend Architecture							 18
      5.1.1. FastAPI Framework							 18
      5.1.2. LangChain Integration						 19
      5.1.3. Database Structure							 21
   5.2. Frontend Implementation						           23
   5.3. Agent-Specific Implementations					 24
      5.3.1. Interviewer Agent						    	 24
      5.3.2. Coach Agent								 25
      5.3.3. Skill Assessor Agent							 26
   5.4. Event-Driven Communication System				           27
6. System Architecture Diagrams					29
   6.1 Interview Agent 								 29
   6.2 Coach Agent									 30
   6.3 Skill Assessor Agent							 31
   6.4 Full System Architecture							 32
7. Conclusion									33
8. References									35















Abstract
	This work describes the creation of an AI-powered Interview Preparation Agent that enables students to work freely, without fear of judgment, and enhance their performance in job interviews. Using the technology of LLMs (large language models), including Google’s Gemini models in LangChain, the system mimics interviews and evaluates verbal feedback, including body language, in real-time. The design is centered on a modular multi-agent architecture that contains specialized interviewing, coaching, and skill assessment agents, which are orchestrated through an event-driven architecture. This configuration enables the system to respond to varying user contexts and interaction preferences while preserving aligned, coherent, and pedagogically sound lines of dialogue. 
	The project demonstrates how generative AI can expand access to career readiness assistance, particularly for students who lack mentorship opportunities. Its execution offers insights into applying sophisticated educational AI technologies for career development.











1. Introduction
1.1. Project Overview
	For everyone going through a job interview, it is indeed one of the most daunting and anxiety-inducing challenges. As someone who had to face the challenging world of internship interviews as a student, I definitely felt that stress. It is one thing to have the required abilities and skills, however, the manner in which one presents himself or herself is just as important (if not more) when it comes to the interview and selection process. With all this in mind, I wanted to make sure that I was doing everything to aid in alleviating this challenge.
elopment.
	That was the idea for my project ‘AI interview agent,’ my very own digital job protégé that could help students get ready for interviews. The concept that I wanted to create was that of an AI coach for everyone to practice whenever they felt like for a job interview without fear of judgment from friends or counselors. The idea of chatting to an AI capable of functioning as an interviewer is indeed very fascinating. The AI provides pertinent feedback regarding the answers provided as well as the body language exhibited during the engagement.
	I constructed this using pretty sophisticated AI technologies - the Large Language Models (LLM) of the day, in particular, I worked with Gemini models from Google in a framework called LangChain. It was certainly a journey for me! The goal was to create an intuitive design that adapts easily to varying contexts and assists you in building your confidence.


1.2. Project Goals
	What I was aiming for was building a prototype that was functional and could assist students in preparing for interviews. This is what I had planned:
1) An AI interviewer that poses version-arrelevant questions depending on the job position you are applying for.
2) A coach agent that provides constructive feedback on your answers, using the STAR method (Situation, Task, Action, Result).
3) A skill-assessor agent that tells you which skills you are confident in and which you are not.
4) A multi-agent system where the AI is broken down to various specialized agents instead of one unified AI trying to control everything.
5) A simple website where the users could attend practice interviews and get feedback.
6) Rather than focusing on building every fancy feature, I concentrated on building the core architecture, which is getting the structure right. 

1.3. Report Structure
	This is the report that narrates the journey of building the AI Interviewer Agent. First, I state my reasoning behind the problem, and then outline the specific aims that I’m looking to achieve. Following that, I explain my solution, what I will supported the multi-agent system with, as well as system architecture and technology of my outline. Then, I present the features of my system, the challenges of implementation, as well as my other thoughts for future work, and finally, I conclude with the insights gained from the project.


2. Motivation
2.1. Interview Skills Importance
	I can picture my first big internship interview as clear as day – and I remember absolutely failing it. They wanted technical skills, which I had, but completely bombed when they asked me “describe a time when you showed leadership.”
	Employers are always on the look out for candidates who are good communicators and possess the so-called soft skills. And that is why we say, the dream job is hidden behind an all-important and rather tricky interview, for which, mastering interview skills is a completely different context from what we are taught in class.
	So, for the rest of us who are early in our careers, the performance in an interview that lasts 30-60 minutes can make or break our chances at landing our very first job. So as you can guess, learning how to expertly navigate an interview for a job is crucial, which is sadly, most of us don’t know how to do.

2.2. Traditional Practice Challenges
	Most conventional methods of preparing for interviews come with their own unique sets of challenges.

Published interview prep books: They say there are one of a kind virtual swimming coaches that allow students to swimvia screen– takes the fun away. Learning all too basic (and ubiquitous) top ten interview questions with IVY-league and MBB paraphrased phrases does absolutely nothing when faced with real life.

Practicing solo: You won’t believe some of the rituals polished professionals grade themselves on when it comes to answering questions. Most of them involve being positioned in front of a mirror.

Career guidance from family and friends - They're excessively kind ("Good job!" when it was a complete disaster lol) or lack the knowledge to pose realistic questions. Career centers in the university are typically overloaded.

2.3. AI Potential
This is where AI comes in. Thanks to advancements in large language models, these systems can now speak in a human-like manner.

•	These AI systems could address many issues encountered with traditional interview practice:
•	They can create realistic interview questions and simulate follow-up questions.
•	They can evaluate your answers and pinpoint regions that need improvement.
•	They offer tailored suggestions.
•	They are accessible all the time.
•	There’s no embarrassment or shame for errors.

I was really pumped about the possibility of incorporating all these advantages into an AI interview coach.



3. Problem Statement
3.1. Lack of Practice Tools
	A huge problem is the clear lack of meaningful practice opportunities for interviews. Career centers provide a few mock interviews, while other accessible online tools are simply lists of questions devoid of personalization specific to the user’s job target.
For example, during my preparation for a software engineering position, I used a generic question bank and was flabbergasted at the actual interview which focused on data structures.

1.	Students need solutions that are:
2.	Available on demand.
3.	Custom designed for particular jobs.
4.	Knowledgeable of user background
5.	Cost effective.

3.2. Need for Realism
	There is a considerable difference between working on practice problems and sitting in an interview. I have had the experience of feeling prepared in a mock interview scenario, but completely blanking out in front of the actual interviewer because of the following:
 
- There is a degree of pressure in interviews.
- Interviewers have windows to ask follow up questions; they do.
- You have to be quick on your feet in real time decision making.
- Conversations happen without a set structure.

4. AI Interviewer Solution
4.1. Concept
My vision was to create a web application that allows you to:
- Specify what role you’re applying for.
- Let my system analyze the provided resume.
- Simulate conversation with an AI Interviewer.
- Provide instantaneous feedback.
- Illustrate which particular skills are being exhibited.
	In my vision, there would be a sense of having a personal interview coach without paying a fortune; something that is engaging and actually beneficial, without hidden interactions and technical difficulties.

4.2. Multi-Agent System
	Rather than hyper focusing on a single AI model to do everything, I designed a system with three specialized agents.

1. The Interviewer Agent: Carries out the interview – poses appropriate questions and manages the narrative.

2. The Coach Agent: Evaluates how you are responding. Is your answer well formulated? Are you responding using the STAR framework? Communication feedback is offered by The Coach.  

3. The Skill Assessor Agent: Determines which skills you have been able to demonstrate are associated

4.3. Technical Architecture
	The AI Interviewer Agent relies on a service-oriented technical architecture that properly separates different operational components. The system implements an architecture based on microservices when agents act as standalone services that communicate through defined events sent over the event bus.
	The system architecture has four main layers which function independently to deliver its operations.

1. The Next.js frontend at the presentation layer handles user interactions while showing responses to users.
2. The FastAPI backend operates within the API Gateway Layer to handle authentication and HTTP requests which directs those requests to target services.
3. The Agent Layer hosts three specialized intelligent agents which execute particular duties.
   - Interviewer Agent
   - Coach Agent
   - Skill Assessor Agent

4. The Data Persistence Layer makes use of a SQLite database which maintains session information together with user responses and evaluation metrics.

	The design deploys multiple layers which make it possible to build modules independently and lets users maintain the system with ease. The API Gateway operates as the central controlling entity that manages the communication between different layers which use standardized protocols.

	Through its event bus mechanism the system applies the Observer design pattern which enables disconnected subscription for specific events. Additional agents can be added to the system without changing current components because of this configuration which enhances system extensibility.

4.4. Agent Implementation Details

Each agent in the system comes with a particular technical architecture designed to fulfill its specific purpose:

1. Interviewer Agent:

- Utilizes state machine design patterns to handle interview progress.
- Uses context-aware prompt templates that include the job description and the resume.
- Employs elaborate prompt engineering techniques using system prompts that delineate boundaries for behavior.
- Keeps track of the conversation history using a sliding context window of 4000 tokens.
- Applies context windows with a sliding scale of 0.7 for temperature control to maintain consistency without sacrificing variability in conversation.
- Relies on custom-designed algorithms that retrieve questions from both predefined and generated dynamically-assembled sets.

2. Coach Agent:
- Gives a structure for evaluating answers and providing feedback.
- Evaluates with STAR criteria, clarity, brevity, relevance, and usability with a comprehensive weighted rubric system.
- Uses output structure formatting with LangChain output parsers.
- Prevents feedback suggestion redundancy by maintaining history.
- Encourages response exemplars with few-shot learning techniques to enhance consistency.

3. Skill Assessor Agent:
- Develops and uses a skill taxonomy database based on hierarchical classification of technical and soft skills.
- Detects quoted skills through named entity recognition techniques.
- Utilizes semantic similarity analysis to match indirect skill demonstrations.
- Tracks all skills demonstrated cumulatively in an interview session.

Uses gap analysis algorithms to determine relevant unarticulated competencies for the specified job. The agents are defined as Python classes that subclass an abstract BaseAgent class, which manages the shared functionality associated with LLM communication, error management, and event management.

4.5. Communication Protocol
	Agent interaction is enabled through usage of an in-house developed event bus system. Such system architecture enables loose coupling among components and monoliths. Event buses have some notable pieces of technical equipment which include:
1. Informal event subclasses exhibiting the particular type of information being transmitted:
- QuestionGeneratedEvent
- UserResponseEvent
- FeedbackGeneratedEvent
- SkillAssessmentEvent
- SessionStateEvent 
2. Event Handling Through Python's asyncio Library: Non-blocking event handling occurs via the use of asynchronous operations.
3. Type validation via Pydantic models ensures consistency in event serialization. This is referred to as the messages’ Serialization. 
4. Non-critical events are executed after critical ones have been handled, this is achieved through a priority message queue. 

The flow of events is conducted as follows:

1. Coach Agent and Skill Assessor Agent receive user response simultaneously
2. Interview Agent generates a question (QuestionGeneratedEvent)
3. User response (UserResponseEvent)
4. Both agents process and produce their corresponding outputs (FeedbackGeneratedEvent, SkillAssessmentEvent)
5. Orchestrator collects outputs and refreshes session state (SessionStateEvent)
6. Interviewer Agent receives new session state and produces next question.




5. System Implementation
5.1. Backend Architecture
	The backend of the AI Interviewer Agent is built with a focus on scalability, maintainability, and performance. It serves as the computational core where the intelligent agents operate and interact with external services.

5.1.1. FastAPI Framework
	Various reasons, both technical and non-technical, explain why FastAPI was selected web framework:

1. Ease of Use with Asynchronous Calls: FastAPI representing higher-level frameworks provide asynchronous request handling which is a huge benefit for managing multiple concurrent interview sessions and doing LLM API calls which take several seconds to return.

2. Use of Pydantic Models: FastAPI provides an integration with Pydantic which allows for runtime type checking, this leads to a closed system which system ensures security in various system components.

3. Automated OpenAPI Documentation: It can automatically provide interactive debuggable document for testing and integrating with the system's APIs enabling easier debugging during integration testing.

4. FastAPI has an advanced dependency injection which empowers to solve problems of separation of concerns. Advanced unit testing is done by directing mocks for mock during such simplified systems.

The API endpoints are organized following RESTful principles with resource-based URL structures:
- `/api/sessions` - Managing interview sessions
- `/api/questions` - Question generation and retrieval
- `/api/responses` - Handling user responses
- `/api/feedback` - Accessing coach feedback
- `/api/skills` - Retrieving skill assessments

5.1.2. LangChain Integration
LangChain is an library that abstracts the complexity needed to interact with LLMs. It includes:

1. Custom chains for each agent that process individual inputs through multiple transformations: Change composition specialization. 
   - Interrogator chains: context → question creation → answer comformation
   - Assistant chains: response → evaluation → feedback change
   - Skill chains: Parsing response→ Skill extraction → Gap analysis

2. Prompt Templates: Specialized templates with role-based formatting:
   ```
   template = """
   System: You are an expert interviewer for {job_role} positions.
   Context: {resume_summary}
   Job Description: {job_description}
   Interview Progress: {interview_history}
   
   Generate the next interview question that evaluates the candidate's fit for this role.
   """
   ```
3. Memory Management: Implementation of proprietary strategies for managing memory in relation to conversation history:

Sliding window memory for the Interviewer Agent
Summary memory for the Coach Agent to monitor and manage reoccurring problems

Cumulative memory for the Skill Assessor to facilitate a comprehensive skill profile

4. LLM Configuration: Parameter settings for Gemma 3 are tailored for precision:
Temperature: Set at 0.7 for Interview, to allow for extra creativity; 0.2 for Coach and Skill Assessor for increased determinism.
Top-p: 0.9 to ensure some non-predictable randomness
Max tokens: A flexible limit based on the anticipated answer length responds
Presence penalty: 0.6 to avoid excessive repetition

5.1.3. Database Structure

The system uses SQLite for data persistence with a relational schema optimized for interview session tracking:

1. Sessions Table: Stores metadata about each interview session:
   - session_id (PK)
   - user_id
   - job_role
   - start_timestamp
   - end_timestamp
   - status

2. Questions Table: Records questions asked during sessions:
   - question_id (PK)
   - session_id (FK)
   - question_text
   - question_type (behavioral, technical, situational)
   - timestamp
   - sequence_number

3. Responses Table: Captures user answers:
   - response_id (PK)
   - question_id (FK)
   - response_text
   - response_duration
   - timestamp

4. Feedback Table: Stores coaching feedback:
   - feedback_id (PK)
   - response_id (FK)
   - structure_score
   - clarity_score
   - relevance_score
   - feedback_text
   - improvement_suggestions

5. Skills Table: Tracks skill assessments:
   - skill_id (PK)
   - name
   - category
   - description

6. SkillDemonstrations Table: Many-to-many relationship between responses and skills:
   - demonstration_id (PK)
   - response_id (FK)
   - skill_id (FK)
   - confidence_score
   - evidence_text

The schema of the database defines foreign key constraints for preserving referential integrity and creates indexes on the most frequently accessed columns to improve performance.


5.2. Frontend Implementation
Frontend architecture is built using Next.js and React and is component-based, focusing on maintainability and improved user experience. Technical features of significance include:

1. State Management
- React Context API for global state (interview session, user profile)
- React Query for managing server state, with caching and background refetching
- UI-specific interaction local component state

2. Architectural Elements:
- Atomic design pattern with atoms, molecules, organisms, and templates
- Cross-cutting concern higher-order components (loading states, error handling)
- Custom reusable logic hooks (useInterview, useFeedback, useSkillAssessment)

3. API Integration:
- Axios for HTTP requests with request/response interceptors
- Typed response custom API client with TypeScript interfaces
- Positive reinforcement towards enhanced perceived performance

4. Styling and Responsiveness:
- Tailwind CSS utility-first styling
- Theming tokens with custom design
- Responsive design with mobile-first approach

5. Accessibility:
- ARIA attributes for screen reader support - Keyboard navigation support - Color contrast accessibility The frontend talks to the backend via RESTful API calls, with appropriate error handling and loading states to offer a smooth user experience.

5.3. Agent-Specific Implementations
5.3.1. Interviewer Agent
	Interviewer is responsible for the complete interview process. He has to formulate the context and create suitable examination questions. Its implementation constitutes:  

1.Pipeline for Generation of Questions:  
- Context Preparation: Fetches relevant information from the resumes and job descriptions.  
- Question Selection Algorithm: Chooses from a static pool of question banks as well as from dynamically created questions.  
- Question Adaptation: Modifies based on prior answers given and skill gaps detected.  
- Follow-up Identification: Determines that a follow-up question as opposed to a new one based on a different heading is needed.  

2. Strategic Blend of Technical interview
- States: Introduction, Skill assessment, Behavioral assessment, Validation of Technical Skills, Wrap-up.  
- Transitions: It relies on the quality of user responses, time constraints, and coverage gaps.  
- Guards: Preconditioned requirements that need to be met before state transitions are cross-checked.  

3. Response Analysis:
    - Semantic Understanding: In this case the term means extracting topics from user’s (and other participant’s) replies.
    - Length Analysis: Analysis of degree of elaborateness of the reply. It user elaborate too much or not.
    - Comprehensiveness Detection: Determines whether the answer given fully responds to the provided question.

The Interviewer Agent uses advanced prompt design, including system directions, user context, and chat history to maintain coherence and continuity in conversation.

5.3.2. Coach Agent
The Coach Agent provides feedback based on effectiveness criteria by analyzing user feedback. Its implementation is technical, including:
1. Evaluation Framework:
   - STAR Analysis Module: Looks for balance in presence of Situation, Task, Action, and Result components.
   - Grammar: Checks for correct sentence, word, and coherent structure.
- Relevance Detector: Evaluates matching the intention behind a question and the provided answer's content.
- Quantitative Scoring: Streamlines scoring for every dimension to a metric in a 1 to 5 scale range.

2. Feedback Generation System:  
- Prioritization Algorithm: Scans for explicit critical areas that require attention for optimization.
- Answer Suggestion Algorithm: Its a predefined suggestions to show how to provide better formulated improved answers.
- Constructive Criticism: Balances between criticism and appreciation of strong areas identified

3. Personalization Engine: 
- Adaptive Session Tracking: Measures  progress tracking across multiple feedback sessions held.
- User-Centric Responsive Feedback: Apres delivers prompted tailored feedback that meets stage expectations career users are within.
- Sector Benchmarked Criterion Tailoring: Applied sector focus benchmarks are criteria to differing sectors.

The prompt exemplars adhere to few-shot learning when automating provided feedback standards.

5.3.3. Skill Assessor Agent
The Skill Assessor Agent observes and records the skills shown in user answers. Its technical development incorporates:

1. Skill Framework Structure:
   - Nomenclatural Taxonomy: Arranges skill sets within domain-specific trees
   - Skill Network Diagram: Illustrates relationships between interdependent skills
   - Specialized Translation Glossaries: Captures variations of definitions in different industries

2. Skills Recognition Process:
   - Skill Mentions Extraction: Detection of direct references to skills
   - Skill Depiction Evaluation: Activates skills based on described activities
   - Confidence Estimation: Measurement of probability to identified skills

3. Gap Analysis Engine
   - Job Requirement Parser: Analyzes the attached job description to gather skills
   - Recommendation Draft: Suggests skills that the user should work on.

5.4. Event-Driven Communication System
	Implementing the Event bus serves as the backbone of the application enabling communication between components with no dependencies or relations. It gives the following features: 

1. Structure of the Event Message: 
- Event Type: Indicates the type of event one of predefined enumeration values
- Payload: Is of certain data type which contains the information related for the event 
- Metadata: Comprises timestamp, source component, correlation ID.

2. Subscription Registry: 
- Implementation of Observer Pattern: It enables component registration for event notification. 
- Topic-Based Filtering: Ability to filter events selectively. 
- Dynamic Registration: Registration and deregistration of components can be accomplished during run time.

3. Message Processing Guarantees:
- In-Memory Queue: Buffers events during periods of high-load processing. 
- Handling Error: For events that have failed after multiple attempts to process them, applying retry logic takes place.
- Dead Letter Queue: Holds events that have failed execution after excessive attempts.


4. Other Considerations:
- Logging: Detailed event tracing for better debugging 
- Monitoring: Measures and records Event processing time metrics
 - Serialization: Changes events into a standard form to Increase data durability.
  
The event bus enables a fully reactive architecture whwere components implicity respond to system events as opposed to system invocation resulting to an easier maintained and modified system.


6. System Architecture Diagrams
6.1 Interview Agent 
 
6.2 Coach Agent
 
6.3 Skill Assessor Agent
 
6.4 Full System Architecture
 
7. Conclusion

	The application of Large Language Models to tackle the practically set problem of interview preparation captures a benchmark when it comes to automation: The AI Interviewer Agent is a case in point. By applying a multi-agent system with domain-specific components, the project illustrates that sophisticated metacognitive activities can be performed in a stepwise manner.
 
	The technical design form of the system, which revolves around an event-driven form of communication, is very adaptable in terms of adding new functions and meeting changing needs. Divide and conquer problem-solving enables the integration of the Interviewer, Coach, and Skill Assessor agents into one user-friendly system whereby each agent focuses on their primary function and creates added value within their core competence.

	This was an extensive project from an educational point of view and it enabled for the first time to improve know-how related to modern IT for higher education on:

- Creating and deploying applications based on service oriented architecture
- Utilizing advanced technologies based on LLMs, such as Gemma 3
- Building asynchronous event driven systems 
- Integrating user experience with technical sophistication

Even though the current implementation has room for improvement, it illustrates how AI can provide personalized and easily accessible interview practice, overcoming the challenges posed by traditional systems.

The varying types of prompt engineering, designing system architecture, and other elements related to this project demonstrate that this work is broader than just applying a solution; it is an example of learning AI systems design, which is critical in today’s world.

Many students struggle with interview preparation, and such tools have the potential to greatly aid those who lack access to career coaching, thereby contributing to that aspect.


8. References:

1. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S., & Kiela, D. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In *Proceedings of the 34th Conference on Neural Information Processing Systems (NeurIPS)*, 9459–9468.

2. Johnson, J., Douze, M., & Jégou, H. (2019). Billion-scale similarity search with GPUs. *IEEE Transactions on Big Data*, 7(4), 700–708. https://doi.org/10.1109/TBDATA.2019.2921572

3. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. In *Advances in Neural Information Processing Systems (NeurIPS)*, 35, 24824–24837.

4. Yao, S., Li, B., Chen, M., Zhao, L., Pan, H., Lin, X. V., et al. (2024). Planning with Language Models for Dialogue Agents. In *Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)*, 2024.

5. Park, J., O'Brien, J., Suresh, S., Zhang, A., Donahue, C., Saunders, W., & Newton, C. (2024). Generative Agents: Interactive Simulacra of Human Behavior. In *Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI)*.
